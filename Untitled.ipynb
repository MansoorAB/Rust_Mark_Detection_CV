{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ca57d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),  \n",
    "    'VIDEO_PATH': os.path.join('Tensorflow', 'workspace','videos'), \n",
    "    'OD_OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','od_output'), \n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "#     'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "#     'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "#     'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "#     'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7cd4fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths.update({    \n",
    "    'COLLECTED_IMAGES': os.path.join('Tensorflow', 'workspace', 'images', 'collectedimages1'),\n",
    "    'TRAIN_PATH': os.path.join('Tensorflow', 'workspace', 'images', 'train'),\n",
    "    'TEST_PATH': os.path.join('Tensorflow', 'workspace', 'images', 'test'),\n",
    "    'ARCHIVE_PATH': os.path.join('Tensorflow', 'workspace', 'images', 'archive.tar.gz')    \n",
    " })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a464ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WORKSPACE_PATH': 'Tensorflow\\\\workspace',\n",
       " 'SCRIPTS_PATH': 'Tensorflow\\\\scripts',\n",
       " 'APIMODEL_PATH': 'Tensorflow\\\\models',\n",
       " 'ANNOTATION_PATH': 'Tensorflow\\\\workspace\\\\annotations',\n",
       " 'IMAGE_PATH': 'Tensorflow\\\\workspace\\\\images',\n",
       " 'VIDEO_PATH': 'Tensorflow\\\\workspace\\\\videos',\n",
       " 'OD_OUTPUT_PATH': 'Tensorflow\\\\workspace\\\\od_output',\n",
       " 'MODEL_PATH': 'Tensorflow\\\\workspace\\\\models',\n",
       " 'PRETRAINED_MODEL_PATH': 'Tensorflow\\\\workspace\\\\pre-trained-models',\n",
       " 'PROTOC_PATH': 'Tensorflow\\\\protoc',\n",
       " 'COLLECTED_IMAGES': 'Tensorflow\\\\workspace\\\\images\\\\collectedimages1',\n",
       " 'TRAIN_PATH': 'Tensorflow\\\\workspace\\\\images\\\\train',\n",
       " 'TEST_PATH': 'Tensorflow\\\\workspace\\\\images\\\\test',\n",
       " 'ARCHIVE_PATH': 'Tensorflow\\\\workspace\\\\images\\\\archive.tar.gz'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62aff095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1 file(s) copied.\n",
      "Images from Tensorflow\\workspace\\images\\collectedimages1\\Low are now partitioned into train and test datasets\n",
      "Images from Tensorflow\\workspace\\images\\collectedimages1\\Moderate are now partitioned into train and test datasets\n",
      "Images from Tensorflow\\workspace\\images\\collectedimages1\\Severe are now partitioned into train and test datasets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.name=='nt':\n",
    "    partition_file = os.path.join(paths['SCRIPTS_PATH'], 'partition_dataset.py')\n",
    "    !copy {partition_file} partition_dataset.py\n",
    "\n",
    "i = 0\n",
    "\n",
    "for rootdir, subdir, files in os.walk(paths['COLLECTED_IMAGES']):\n",
    "#     print (i, rootdir, subdir, files, '\\n')\n",
    "    if i == 0:\n",
    "        if len(files) > 0 :\n",
    "            if len(subdir) > 0:\n",
    "                print('The folder \"{}\" should contain either subfolder or files, but not both!'.format(rootdir))\n",
    "                break;\n",
    "            else:\n",
    "                !python partition_dataset.py -x -i {paths['COLLECTED_IMAGES']} -o {paths['IMAGE_PATH']} -r 0.2\n",
    "    else: \n",
    "        if len(subdir) > 0:\n",
    "            print('The folder \"{}\" should contain only files but not any subfolders!'.format(rootdir))\n",
    "            break;\n",
    "        if len(files) == 0:\n",
    "            print('The folder \"{}\" should contain 2 or more files.'.format(rootdir))\n",
    "            break;\n",
    "        else:\n",
    "            !python partition_dataset.py -x -i {rootdir} -o {paths['IMAGE_PATH']} -r 0.5       \n",
    "            \n",
    "    i += 1\n",
    "    \n",
    "if os.name=='nt':\n",
    "    !del partition_dataset.py      \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336436fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rust_detection",
   "language": "python",
   "name": "rust_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
